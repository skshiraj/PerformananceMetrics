{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sugurunaresh111_gmail.com_05.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"s0Ej_bXyQvnV"},"source":["# Compute performance metrics for the given Y and Y_score without sklearn"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4CHb6NE7Qvnc","outputId":"ddf116ce-9770-4ae5-ca6d-18e5e612df76","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt \n","data = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\PerformananceMetrics-master\\\\5_a.csv\") \n","data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10100, 2)"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lowX6Lo6M1HX"},"source":["# **Confusion Matrix**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KbsWXuDaQvnq"},"source":["<pre>\n","<font color='red'><b>A.</b></font> Compute performance metrics for the given data <strong>5_a.csv</strong>\n","   <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n","   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n","   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n","\n","<pre>\n","<ol>\n","<li> Compute Confusion Matrix </li>\n","<li> Compute F1 Score </li>\n","<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)</li>\n","<li> Compute Accuracy Score </li>\n","</ol>\n","</pre>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YhM8y_-aMxCB","outputId":"f381bfb8-14cc-4167-d304-4912b24de376","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","def label(proba):\n","  if proba>0.5:\n","    return 1.0\n","  else:\n","    return 0.0\n","\n","data = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\PerformananceMetrics-master\\\\5_a.csv\") \n","data['Y_Pred'] = data.apply(lambda row:label(row.proba),axis=1)\n","data.shape\n","\n","TN=0\n","FN=0\n","FP=0\n","TP=0\n","for i in range(len(data.Y_Pred)):\n","  if data.iloc[i][0]==0:    #actual value=0\n","    if data.iloc[i][2]==0:\n","      TN=TN+1\n","    elif data.iloc[i][2]==1:\n","      FP=FP+1\n","  elif data.iloc[i][0]==1:  #actual value=1\n","    if data.iloc[i][2]==0:\n","      FN=FN+1\n","    elif data.iloc[i][2]==1:\n","      TP=TP+1    \n","print(TN,FN,FP,TP)\n","\n","#F1-score:\n","P=0\n","N=0\n","TPR=0\n","Pr=0\n","Re=0\n","F1=0\n","for i in range(len(data.Y_Pred)):\n","  if data.iloc[i][0]==1:\n","    P=P+1\n","print(P)\n","for i in range(len(data.Y_Pred)):\n","  if data.iloc[i][0]==0:\n","    N=N+1\n","print(N)\n","\n","TPR=TP/P\n","Re=TPR\n","print(TPR)\n","Pr=(TP/(TP+FP))\n","print(Pr)\n","F1=((Pr*Re*2)/(Pr+Re))\n","print(F1)\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["0 0 100 10000\n","10000\n","100\n","1.0\n","0.9900990099009901\n","0.9950248756218906\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zU9WqsAIyvYR","outputId":"15653327-ec1a-4bc2-8355-a2c791d94f33","colab":{}},"source":["Y_Unique=data['proba'].unique()\n","p=np.round(Y_Unique,3)#rounding the threshold values to reduce NUmber of Thresholds\n","Y_Unique=np.unique(p)\n","Y_Sorted=sorted(Y_Unique, reverse=True)\n","print(len(Y_Sorted))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["401\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zg7MC8_L_h4v"},"source":["# **Threshold**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UA_pH1v3aLUd","colab":{}},"source":["from tqdm import tqdm\n","FPR=[]\n","TPR=[]\n","def label(proba,Y):\n","  if proba>Y:\n","    return 1.0\n","  else:\n","    return 0.0\n","for j in tqdm(range(len(Y_Sorted))):\n","  j=j\n","  TP=0\n","  FP=0\n","  data['Y_Pred'] = data.apply(lambda row:label(row.proba,Y_Sorted[j]),axis=1)\n","  print(Y_Sorted[j])\n","  for i in range(len(data.Y_Pred)):\n","    if data.iloc[i][0]==0 and data.iloc[i][2]==1:\n","        FP=FP+1\n","    elif data.iloc[i][0]==1 and data.iloc[i][2]==1:\n","        TP=TP+1 \n","  #print(TP,FP)    \n","  TPR.append(TP/P)\n","  FPR.append(FP/N)\n","print(TPR)\n","print(FPR)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g5kAaCYGTeH_","outputId":"024cedbf-7cda-423f-c52d-f3e3d8912e7a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pAUC = np.trapz(TPR,FPR)\n","print(pAUC)\n","plt.plot(TPR,FPR)\n","Accuracy=((TP+TN)/(TP+TN+FP+FN))\n","print('Accuracy:',Accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.488309\n","Accuracy: 0.9900990099009901\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"fZAHsmJbJenX","colab_type":"text"},"source":["<pre>\n","<font color='red'><b>B.</b></font> Compute performance metrics for the given data <strong>5_b.csv</strong>\n","   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n","   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n","   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n","\n","<pre>\n","<ol>\n","<li> Compute Confusion Matrix </li>\n","<li> Compute F1 Score </li>\n","<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a></li>\n","<li> Compute Accuracy Score </li>\n","</ol>\n","</pre>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wZ5cccNeyvYd","colab":{}},"source":["\n","def label(proba):\n","  if proba>0.5:\n","    return 1.0\n","  else:\n","    return 0.0\n","\n","\n","data = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\PerformananceMetrics-master\\\\5_b.csv\") \n","data.shape\n","data['Y_Pred'] = data.apply(lambda row:label(row.proba),axis=1)\n","TN=0\n","FN=0\n","FP=0\n","TP=0\n","for i in range(len(data.Y_Pred)):\n","  if data.iloc[i][0]==0:    #actual value=0\n","    if data.iloc[i][2]==0:\n","      TN=TN+1\n","    elif data.iloc[i][2]==1:\n","      FP=FP+1\n","  elif data.iloc[i][0]==1:  #actual value=1\n","    if data.iloc[i][2]==0:\n","      FN=FN+1\n","    elif data.iloc[i][2]==1:\n","      TP=TP+1    \n","print(TN,FN,FP,TP)\n","\n","#F1-score:\n","P=0\n","N=0\n","TPR=0\n","Pr=0\n","Re=0\n","F1=0\n","for i in range(len(data.Y_Pred)):\n","  if data.iloc[i][0]==1:\n","    P=P+1\n","print(P)\n","for i in range(len(data.Y_Pred)):\n","  if data.iloc[i][0]==0:\n","    N=N+1\n","print(N)\n","\n","TPR=TP/P\n","Re=TPR\n","print(TPR)\n","Pr=(TP/(TP+FP))\n","print(Pr)\n","F1=((Pr*Re*2)/(Pr+Re))\n","print(F1)\n","\n","Y_Unique=data['proba'].unique()\n","p=np.round(Y_Unique,3)#rounding the threshold values to reduce NUmber of Thresholds\n","Y_Unique=np.unique(p)\n","Y_Sorted=sorted(Y_Unique, reverse=True)\n","print(len(Y_Sorted))\n","\n","\n","from tqdm import tqdm\n","FPR=[]\n","TPR=[]\n","def label(proba,Y):\n","  if proba>Y:\n","    return 1.0\n","  else:\n","    return 0.0\n","for j in tqdm(range(len(Y_Sorted))):\n","  j=j\n","  TP=0\n","  FP=0\n","  data['Y_Pred'] = data.apply(lambda row:label(row.proba,Y_Sorted[j]),axis=1)\n","  print(Y_Sorted[j])\n","  for i in range(len(data.Y_Pred)):\n","    if data.iloc[i][0]==0 and data.iloc[i][2]==1:\n","        FP=FP+1\n","    elif data.iloc[i][0]==1 and data.iloc[i][2]==1:\n","        TP=TP+1 \n","  #print(TP,FP)    \n","  TPR.append(TP/P)\n","  FPR.append(FP/N)\n","print(TPR)\n","print(FPR)\n","\n","\n","pAUC = np.trapz(TPR,FPR)\n","print(pAUC)\n","plt.plot(TPR,FPR)\n","Accuracy=((TP+TN)/(TP+TN+FP+FN))\n","print('Accuracy:',Accuracy)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GiPGonTzQvoB"},"source":["<font color='red'><b>C.</b></font> Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric for the given data <strong>5_c.csv</strong>\n","<br>\n","\n","you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n","\n","$ A = 500 \\times \\text{numebr of false positives} + 100 \\times \\text{numebr of false negatives}$\n","\n","<pre>\n","   <b>Note 1:</b> in this data you can see number of positive points < number of positive points\n","   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n","</pre>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3c7Zcs1WyvYg","outputId":"57061016-7385-4488-fd55-d131ff4bcd33","colab":{}},"source":["\n","def label(proba):\n","  if proba>0.5:\n","    return 1.0\n","  else:\n","    return 0.0\n","\n","data = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\PerformananceMetrics-master\\\\5_c.csv\") \n","data.shape\n","data['Y_Pred'] = data.apply(lambda row:label(row.prob),axis=1)\n","TN=0\n","FN=0\n","FP=0\n","TP=0\n","for i in range(len(data.Y_Pred)):\n","  if data.iloc[i][0]==0:    #actual value=0\n","    if data.iloc[i][2]==0:\n","      TN=TN+1\n","    elif data.iloc[i][2]==1:\n","      FP=FP+1\n","  elif data.iloc[i][0]==1:  #actual value=1\n","    if data.iloc[i][2]==0:\n","      FN=FN+1\n","    elif data.iloc[i][2]==1:\n","      TP=TP+1    \n","print(TN,FN,FP,TP)\n","\n","#F1-score:\n","P=0\n","N=0\n","TPR=0\n","Pr=0\n","Re=0\n","F1=0\n","for i in range(len(data.Y_Pred)):\n","  if data.iloc[i][0]==1:\n","    P=P+1\n","print(P)\n","for i in range(len(data.Y_Pred)):\n","  if data.iloc[i][0]==0:\n","    N=N+1\n","print(N)\n","\n","TPR=TP/P\n","Re=TPR\n","print(TPR)\n","Pr=(TP/(TP+FP))\n","print(Pr)\n","F1=((Pr*Re*2)/(Pr+Re))\n","print(F1)\n","\n","Y_Unique=data['prob'].unique()\n","p=np.round(Y_Unique,2)#rounding the threshold values to reduce NUmber of Thresholds\n","Y_Unique=np.unique(p)\n","Y_Sorted=sorted(Y_Unique, reverse=True)\n","print(len(Y_Sorted))\n","\n","\n","from tqdm import tqdm\n","FPR=[]\n","TPR=[]\n","def label(proba,Y):\n","  if proba>Y:\n","    return 1.0\n","  else:\n","    return 0.0\n","A_min=0\n","thres_max=0\n","for j in tqdm(range(len(Y_Sorted))):\n","    #j=j*100\n","    TP=0\n","    FP=0\n","    TN=0\n","    FN=0\n","    if j==0:\n","        data['Y_Pred'] = data.apply(lambda row:label(row.prob,Y_Sorted[j]),axis=1)\n","    #print(Y_Sorted[j])\n","        for i in range(len(data.Y_Pred)):\n","            if data.iloc[i][0]==0 and data.iloc[i][2]==1:\n","                FP=FP+1\n","            elif data.iloc[i][0]==1 and data.iloc[i][2]==1:\n","                TP=TP+1 \n","            elif data.iloc[i][0]==0 and data.iloc[i][2]==0:\n","                TN=TN+1\n","            elif data.iloc[i][0]==1 and data.iloc[i][2]==0:\n","                FN=FN+1\n","        A_min=((500*FP)+(100*FN))\n","        thres_max=Y_Sorted[0]\n","    else:\n","        data['Y_Pred'] = data.apply(lambda row:label(row.prob,Y_Sorted[j]),axis=1)\n","        #print(Y_Sorted[j])\n","        for i in range(len(data.Y_Pred)):\n","            if data.iloc[i][0]==0 and data.iloc[i][2]==1:\n","                FP=FP+1\n","            elif data.iloc[i][0]==1 and data.iloc[i][2]==1:\n","                    TP=TP+1 \n","            elif data.iloc[i][0]==0 and data.iloc[i][2]==0:\n","                TN=TN+1\n","            elif data.iloc[i][0]==1 and data.iloc[i][2]==0:\n","                FN=FN+1\n","        thres=Y_Sorted[j]\n","        A=((500*FP)+(100*FN))\n","        #print(FP,FN)\n","        #print(A)\n","        if A<A_min:\n","            A_min=A\n","            thres_max=thres\n","            #print('A_min:',A)\n","            #print(thres_max)\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1637 462 168 585\n","1047\n","1805\n","0.5587392550143266\n","0.7768924302788844\n","0.65\n","93\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  0%|                                                                                           | 0/93 [00:00<?, ?it/s]\n","  1%|▉                                                                                  | 1/93 [00:02<03:17,  2.15s/it]\n","  2%|█▊                                                                                 | 2/93 [00:04<03:14,  2.14s/it]\n","  3%|██▋                                                                                | 3/93 [00:06<03:11,  2.12s/it]\n","  4%|███▌                                                                               | 4/93 [00:08<03:08,  2.12s/it]\n","  5%|████▍                                                                              | 5/93 [00:10<03:06,  2.11s/it]\n","  6%|█████▎                                                                             | 6/93 [00:12<03:01,  2.09s/it]\n","  8%|██████▏                                                                            | 7/93 [00:14<02:58,  2.07s/it]\n","  9%|███████▏                                                                           | 8/93 [00:16<02:54,  2.06s/it]\n"," 10%|████████                                                                           | 9/93 [00:18<02:51,  2.04s/it]\n"," 11%|████████▊                                                                         | 10/93 [00:20<02:49,  2.04s/it]\n"," 12%|█████████▋                                                                        | 11/93 [00:22<02:48,  2.05s/it]\n"," 13%|██████████▌                                                                       | 12/93 [00:24<02:47,  2.07s/it]\n"," 14%|███████████▍                                                                      | 13/93 [00:26<02:43,  2.04s/it]\n"," 15%|████████████▎                                                                     | 14/93 [00:28<02:42,  2.05s/it]\n"," 16%|█████████████▏                                                                    | 15/93 [00:31<02:40,  2.06s/it]\n"," 17%|██████████████                                                                    | 16/93 [00:33<02:38,  2.06s/it]\n"," 18%|██████████████▉                                                                   | 17/93 [00:35<02:42,  2.14s/it]\n"," 19%|███████████████▊                                                                  | 18/93 [00:37<02:36,  2.09s/it]\n"," 20%|████████████████▊                                                                 | 19/93 [00:39<02:32,  2.06s/it]\n"," 22%|█████████████████▋                                                                | 20/93 [00:41<02:29,  2.05s/it]\n"," 23%|██████████████████▌                                                               | 21/93 [00:43<02:27,  2.05s/it]\n"," 24%|███████████████████▍                                                              | 22/93 [00:45<02:25,  2.04s/it]\n"," 25%|████████████████████▎                                                             | 23/93 [00:47<02:22,  2.04s/it]\n"," 26%|█████████████████████▏                                                            | 24/93 [00:49<02:18,  2.01s/it]\n"," 27%|██████████████████████                                                            | 25/93 [00:51<02:16,  2.00s/it]\n"," 28%|██████████████████████▉                                                           | 26/93 [00:53<02:12,  1.98s/it]\n"," 29%|███████████████████████▊                                                          | 27/93 [00:55<02:10,  1.98s/it]\n"," 30%|████████████████████████▋                                                         | 28/93 [00:57<02:11,  2.02s/it]\n"," 31%|█████████████████████████▌                                                        | 29/93 [00:59<02:08,  2.01s/it]\n"," 32%|██████████████████████████▍                                                       | 30/93 [01:01<02:05,  1.99s/it]\n"," 33%|███████████████████████████▎                                                      | 31/93 [01:03<02:03,  1.99s/it]\n"," 34%|████████████████████████████▏                                                     | 32/93 [01:05<02:00,  1.97s/it]\n"," 35%|█████████████████████████████                                                     | 33/93 [01:07<01:56,  1.95s/it]\n"," 37%|█████████████████████████████▉                                                    | 34/93 [01:09<01:53,  1.93s/it]\n"," 38%|██████████████████████████████▊                                                   | 35/93 [01:10<01:51,  1.92s/it]\n"," 39%|███████████████████████████████▋                                                  | 36/93 [01:12<01:49,  1.93s/it]\n"," 40%|████████████████████████████████▌                                                 | 37/93 [01:14<01:48,  1.93s/it]\n"," 41%|█████████████████████████████████▌                                                | 38/93 [01:16<01:45,  1.92s/it]\n"," 42%|██████████████████████████████████▍                                               | 39/93 [01:18<01:42,  1.90s/it]\n"," 43%|███████████████████████████████████▎                                              | 40/93 [01:20<01:40,  1.89s/it]\n"," 44%|████████████████████████████████████▏                                             | 41/93 [01:22<01:37,  1.88s/it]\n"," 45%|█████████████████████████████████████                                             | 42/93 [01:24<01:35,  1.87s/it]\n"," 46%|█████████████████████████████████████▉                                            | 43/93 [01:26<01:33,  1.86s/it]\n"," 47%|██████████████████████████████████████▊                                           | 44/93 [01:27<01:30,  1.85s/it]\n"," 48%|███████████████████████████████████████▋                                          | 45/93 [01:29<01:27,  1.82s/it]\n"," 49%|████████████████████████████████████████▌                                         | 46/93 [01:31<01:24,  1.81s/it]\n"," 51%|█████████████████████████████████████████▍                                        | 47/93 [01:33<01:21,  1.78s/it]\n"," 52%|██████████████████████████████████████████▎                                       | 48/93 [01:34<01:18,  1.75s/it]\n"," 53%|███████████████████████████████████████████▏                                      | 49/93 [01:36<01:16,  1.73s/it]\n"," 54%|████████████████████████████████████████████                                      | 50/93 [01:38<01:13,  1.71s/it]\n"," 55%|████████████████████████████████████████████▉                                     | 51/93 [01:39<01:13,  1.74s/it]\n"," 56%|█████████████████████████████████████████████▊                                    | 52/93 [01:41<01:10,  1.71s/it]\n"," 57%|██████████████████████████████████████████████▋                                   | 53/93 [01:43<01:08,  1.70s/it]\n"," 58%|███████████████████████████████████████████████▌                                  | 54/93 [01:44<01:05,  1.69s/it]\n"," 59%|████████████████████████████████████████████████▍                                 | 55/93 [01:46<01:03,  1.68s/it]\n"," 60%|█████████████████████████████████████████████████▍                                | 56/93 [01:48<01:02,  1.69s/it]\n"," 61%|██████████████████████████████████████████████████▎                               | 57/93 [01:49<01:00,  1.67s/it]\n"," 62%|███████████████████████████████████████████████████▏                              | 58/93 [01:51<00:57,  1.64s/it]\n"," 63%|████████████████████████████████████████████████████                              | 59/93 [01:53<00:55,  1.63s/it]\n"," 65%|████████████████████████████████████████████████████▉                             | 60/93 [01:54<00:53,  1.61s/it]\n"," 66%|█████████████████████████████████████████████████████▊                            | 61/93 [01:56<00:50,  1.59s/it]\n"," 67%|██████████████████████████████████████████████████████▋                           | 62/93 [01:57<00:48,  1.56s/it]\n"," 68%|███████████████████████████████████████████████████████▌                          | 63/93 [01:59<00:46,  1.54s/it]\n"," 69%|████████████████████████████████████████████████████████▍                         | 64/93 [02:00<00:43,  1.51s/it]\n"," 70%|█████████████████████████████████████████████████████████▎                        | 65/93 [02:02<00:41,  1.48s/it]\n"," 71%|██████████████████████████████████████████████████████████▏                       | 66/93 [02:03<00:39,  1.47s/it]\n"," 72%|███████████████████████████████████████████████████████████                       | 67/93 [02:04<00:38,  1.46s/it]\n"," 73%|███████████████████████████████████████████████████████████▉                      | 68/93 [02:06<00:36,  1.44s/it]\n"," 74%|████████████████████████████████████████████████████████████▊                     | 69/93 [02:07<00:34,  1.43s/it]\n"," 75%|█████████████████████████████████████████████████████████████▋                    | 70/93 [02:09<00:32,  1.41s/it]\n"," 76%|██████████████████████████████████████████████████████████████▌                   | 71/93 [02:10<00:30,  1.39s/it]\n"," 77%|███████████████████████████████████████████████████████████████▍                  | 72/93 [02:11<00:28,  1.36s/it]\n"," 78%|████████████████████████████████████████████████████████████████▎                 | 73/93 [02:12<00:26,  1.33s/it]\n"," 80%|█████████████████████████████████████████████████████████████████▏                | 74/93 [02:14<00:24,  1.30s/it]\n"," 81%|██████████████████████████████████████████████████████████████████▏               | 75/93 [02:15<00:23,  1.28s/it]\n"," 82%|███████████████████████████████████████████████████████████████████               | 76/93 [02:16<00:21,  1.27s/it]\n"," 83%|███████████████████████████████████████████████████████████████████▉              | 77/93 [02:17<00:20,  1.25s/it]\n"," 84%|████████████████████████████████████████████████████████████████████▊             | 78/93 [02:19<00:18,  1.23s/it]\n"," 85%|█████████████████████████████████████████████████████████████████████▋            | 79/93 [02:20<00:16,  1.20s/it]\n"," 86%|██████████████████████████████████████████████████████████████████████▌           | 80/93 [02:21<00:15,  1.17s/it]\n"," 87%|███████████████████████████████████████████████████████████████████████▍          | 81/93 [02:22<00:13,  1.14s/it]\n"," 88%|████████████████████████████████████████████████████████████████████████▎         | 82/93 [02:23<00:12,  1.13s/it]\n"," 89%|█████████████████████████████████████████████████████████████████████████▏        | 83/93 [02:24<00:11,  1.12s/it]\n"," 90%|██████████████████████████████████████████████████████████████████████████        | 84/93 [02:25<00:09,  1.09s/it]\n"," 91%|██████████████████████████████████████████████████████████████████████████▉       | 85/93 [02:26<00:08,  1.07s/it]\n"," 92%|███████████████████████████████████████████████████████████████████████████▊      | 86/93 [02:27<00:07,  1.08s/it]\n"," 94%|████████████████████████████████████████████████████████████████████████████▋     | 87/93 [02:28<00:06,  1.07s/it]\n"," 95%|█████████████████████████████████████████████████████████████████████████████▌    | 88/93 [02:29<00:05,  1.05s/it]\n"," 96%|██████████████████████████████████████████████████████████████████████████████▍   | 89/93 [02:30<00:04,  1.04s/it]\n"," 97%|███████████████████████████████████████████████████████████████████████████████▎  | 90/93 [02:31<00:03,  1.03s/it]\n"," 98%|████████████████████████████████████████████████████████████████████████████████▏ | 91/93 [02:32<00:02,  1.02s/it]\n"," 99%|█████████████████████████████████████████████████████████████████████████████████ | 92/93 [02:33<00:01,  1.00s/it]\n","100%|██████████████████████████████████████████████████████████████████████████████████| 93/93 [02:35<00:00,  1.08s/it]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sD4CcgjXQvoL"},"source":["<pre>\n","<font color='red'><b>D.</b></font> Compute performance metrics(for regression) for the given data <strong>5_d.csv</strong>\n","    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n","    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n","<ol>\n","<li> Compute Mean Square Error </li>\n","<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n","<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n","</ol>\n","</pre>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"x5HIJzq1QvoE","colab":{},"outputId":"68318011-d996-4a77-d8ee-0228fa052f07"},"source":["data = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\PerformananceMetrics-master\\\\5_d.csv\") \n","data.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(157200, 2)"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"Nl6uXVNjJenl","colab_type":"code","colab":{},"outputId":"6830ca4a-5128-46f3-df23-342b5b0a36fc"},"source":["#Mean Square Error:\n","from sklearn.metrics import mean_squared_error as mse\n","y_mse_scikit=mse(data.y,data.pred)#using scikit\n","print('y_mse using scikit:',y_mse_scikit)\n","y_mse_diff=np.subtract(data.y,data.pred)#y-y_pred\n","y_mse_sqr=np.square(y_mse_diff)#squaring the diff\n","y_mse_sum=0\n","for i in range(len(y_mse_sqr)):\n","    y_mse_sum=y_mse_sum+y_mse_sqr[i]       \n","y_mse_final=y_mse_sum/len(y_mse_sqr)\n","print('y_mse calculated:',y_mse_final)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["y_mse using scikit: 177.16569974554707\n","y_mse calculated: 177.16569974554707\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NfBKk6mMJeno","colab_type":"code","colab":{},"outputId":"cc45d8de-48da-4fef-fe1c-bb8d237750c6"},"source":["#MAPE\n","y_mape_abs_diff=np.absolute(y_mse_diff)#Absolute difference\n","y_pred_abs=np.absolute(data.pred)\n","y_mape_sum=0\n","y_pred_sum=0\n","for i in range(len( y_mape_abs_diff)):\n","    y_mape_sum=y_mape_sum+y_mape_abs_diff[i]   \n","    y_pred_sum=y_pred_sum+y_pred_abs[i]\n","y_mape_final=y_mape_sum/y_pred_sum\n","print('y_mape calculated:',y_mape_final)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["y_mape calculated: 0.1292719136626988\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wh6zP8-LJens","colab_type":"code","colab":{},"outputId":"d05685cb-53ba-4b0a-e03d-3dbe0032336d"},"source":["#R^2:\n","y_actual_sum=0\n","for i in range(len(data.y)):\n","    y_actual_sum=y_actual_sum+data.y[i] \n","y_actual_avg=y_actual_sum/(len(data.y))\n","print('y_actual_avg:',y_actual_avg)\n","#SS_TOT:\n","SS_TOT_diff=np.subtract(data.y,y_actual_avg)#y-y_pred\n","SS_TOT_SQR=np.square(SS_TOT_diff)#squaring the diff\n","SS_TOT=0\n","for i in range(len(SS_TOT_SQR)):\n","    SS_TOT=SS_TOT+SS_TOT_SQR[i] \n","print('SS_TOT:',SS_TOT)\n","#SS_RES:\n","SS_RES_diff=np.subtract(data.pred,data.y)#y-y_pred\n","SS_RES_SQR=np.square(SS_RES_diff)#squaring the diff\n","SS_RES=0\n","for i in range(len(SS_RES_SQR)):\n","    SS_RES=SS_RES+SS_RES_SQR[i] \n","print('SS_RES:',SS_RES)\n","R_SQR=(1-(SS_RES/SS_TOT))\n","print('R^2 Calculated:',R_SQR)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["y_actual_avg: 66.56208651399491\n","SS_TOT: 638161080.035662\n","SS_RES: 27850448.0\n","R^2 Calculated: 0.9563582786990964\n"],"name":"stdout"}]}]}